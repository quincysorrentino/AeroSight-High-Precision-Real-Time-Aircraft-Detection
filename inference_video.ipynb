{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f38e0057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from: C:\\Users\\qwsor\\.cache\\huggingface\\hub\\models--QuincySorrentino--AeroYOLO\\snapshots\\67e0fb4799f24c7972a6de24f1d3f7cfdc2b48c7\\best.pt\n"
     ]
    }
   ],
   "source": [
    "# Load model from Hugging Face\n",
    "from ultralytics import YOLO\n",
    "from huggingface_hub import hf_hub_download\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "MODEL_PATH = hf_hub_download(\n",
    "    repo_id=\"QuincySorrentino/AeroYOLO\",\n",
    "    filename=\"best.pt\"\n",
    ")\n",
    "\n",
    "# Load the YOLO model\n",
    "model = YOLO(MODEL_PATH)\n",
    "print(f\"Model loaded from: {MODEL_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2998fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video: 1920x1080 @ 30fps, 260 frames\n",
      "Processed 30/260 frames (11.5%) - Active tracks: 1\n",
      "Processed 60/260 frames (23.1%) - Active tracks: 2\n",
      "Processed 90/260 frames (34.6%) - Active tracks: 0\n",
      "Processed 120/260 frames (46.2%) - Active tracks: 0\n",
      "Processed 150/260 frames (57.7%) - Active tracks: 1\n",
      "Processed 180/260 frames (69.2%) - Active tracks: 1\n",
      "Processed 210/260 frames (80.8%) - Active tracks: 0\n",
      "Processed 240/260 frames (92.3%) - Active tracks: 1\n",
      "\n",
      "Processing complete. Output saved to: runs/output.mp4\n",
      "Total frames processed: 260\n"
     ]
    }
   ],
   "source": [
    "# Open video\n",
    "cap = cv2.VideoCapture('test_images/plane2.mp4')\n",
    "\n",
    "# Get video properties (width, height, fps)\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "print(f\"Video: {width}x{height} @ {fps}fps, {total_frames} frames\")\n",
    "\n",
    "# Create video writer for output\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('runs/output.mp4', fourcc, fps, (width, height))\n",
    "\n",
    "# Temporal filtering setup\n",
    "detection_buffer = {}  # Track how many consecutive frames each object appears\n",
    "MIN_CONSECUTIVE_FRAMES = 3  # Only show detections that appear in 3+ frames\n",
    "BUFFER_DECAY = 10  # Reset counter if not seen for this many frames\n",
    "\n",
    "# Process each frame with tracking\n",
    "frame_count = 0\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    frame_count += 1\n",
    "    \n",
    "    # Run inference with tracking (reduces flickering)\n",
    "    results = model.track(\n",
    "        frame,\n",
    "        conf=0.57,              \n",
    "        iou=0.7,               \n",
    "        max_det=10,\n",
    "        imgsz=640,\n",
    "        tracker=\"botsort.yaml\",  \n",
    "        persist=True,          \n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    # Temporal filtering - only keep stable detections\n",
    "    current_track_ids = set()\n",
    "    stable_boxes = []\n",
    "    \n",
    "    if results[0].boxes.id is not None:\n",
    "        for box in results[0].boxes:\n",
    "            track_id = int(box.id[0])\n",
    "            current_track_ids.add(track_id)\n",
    "            \n",
    "            # Increment counter for this track\n",
    "            if track_id not in detection_buffer:\n",
    "                detection_buffer[track_id] = {'count': 0, 'last_seen': frame_count}\n",
    "            \n",
    "            detection_buffer[track_id]['count'] += 1\n",
    "            detection_buffer[track_id]['last_seen'] = frame_count\n",
    "            \n",
    "            # Only keep if seen enough times\n",
    "            if detection_buffer[track_id]['count'] >= MIN_CONSECUTIVE_FRAMES:\n",
    "                stable_boxes.append(box)\n",
    "    \n",
    "    # Decay old tracks\n",
    "    tracks_to_remove = []\n",
    "    for track_id in detection_buffer:\n",
    "        if track_id not in current_track_ids:\n",
    "            if frame_count - detection_buffer[track_id]['last_seen'] > BUFFER_DECAY:\n",
    "                tracks_to_remove.append(track_id)\n",
    "    \n",
    "    for track_id in tracks_to_remove:\n",
    "        del detection_buffer[track_id]\n",
    "    \n",
    "    # Plot only stable detections\n",
    "    annotated_frame = frame.copy()\n",
    "    for box in stable_boxes:\n",
    "        # Get box coordinates\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())\n",
    "        cls = int(box.cls[0])\n",
    "        conf = float(box.conf[0])\n",
    "        track_id = int(box.id[0])\n",
    "        \n",
    "        # Draw bounding box\n",
    "        cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        \n",
    "        # Draw label\n",
    "        label = f\"{results[0].names[cls]} {conf:.2f} ID:{track_id}\"\n",
    "        (label_width, label_height), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)\n",
    "        cv2.rectangle(annotated_frame, (x1, y1 - label_height - 10), (x1 + label_width, y1), (0, 255, 0), -1)\n",
    "        cv2.putText(annotated_frame, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 2)\n",
    "    \n",
    "    out.write(annotated_frame)\n",
    "    \n",
    "    if frame_count % 30 == 0:\n",
    "        print(f\"Processed {frame_count}/{total_frames} frames ({frame_count/total_frames*100:.1f}%) - Active tracks: {len(stable_boxes)}\")\n",
    "\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "\n",
    "print(f\"\\nProcessing complete. Output saved to: runs/output.mp4\")\n",
    "print(f\"Total frames processed: {frame_count}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
